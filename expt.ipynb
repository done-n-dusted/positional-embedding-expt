{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ac1ddb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "from model import Model\n",
    "from tqdm import tqdm\n",
    "\n",
    "context_size = 4\n",
    "n_embed = 32\n",
    "n_hidden = 128\n",
    "xlen = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e97ad46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de515852",
   "metadata": {},
   "outputs": [],
   "source": [
    "rands = torch.randn(xlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf87b2ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.0110, -1.1150, -0.3484, -1.2780, -0.8394,  0.0867,  0.0576,  0.2160,\n",
       "         0.7177,  1.0150,  1.4429, -0.7470,  0.3687,  1.1705,  0.3873, -0.6518,\n",
       "         0.2768,  0.0758, -0.2658,  1.1221])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbc0d261",
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = torch.arange(len(rands) - context_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c759fb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (pos_encoder): PostionalEncoding()\n",
      "  (ff): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=1, bias=True)\n",
      "    (3): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdbaafeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def break_contexts(rands):\n",
    "    ix = torch.arange(len(rands) - context_size)\n",
    "    x = torch.stack([rands[i:i+context_size] for i in ix])\n",
    "    y = torch.stack([torch.tensor([rands[i+context_size]]) for i in ix])\n",
    "    \n",
    "    return list(zip(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "240fb29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = break_contexts(rands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d74c7a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([-2.0110, -1.1150, -0.3484, -1.2780]), tensor([-0.8394])),\n",
       " (tensor([-1.1150, -0.3484, -1.2780, -0.8394]), tensor([0.0867])),\n",
       " (tensor([-0.3484, -1.2780, -0.8394,  0.0867]), tensor([0.0576])),\n",
       " (tensor([-1.2780, -0.8394,  0.0867,  0.0576]), tensor([0.2160])),\n",
       " (tensor([-0.8394,  0.0867,  0.0576,  0.2160]), tensor([0.7177])),\n",
       " (tensor([0.0867, 0.0576, 0.2160, 0.7177]), tensor([1.0150])),\n",
       " (tensor([0.0576, 0.2160, 0.7177, 1.0150]), tensor([1.4429])),\n",
       " (tensor([0.2160, 0.7177, 1.0150, 1.4429]), tensor([-0.7470])),\n",
       " (tensor([ 0.7177,  1.0150,  1.4429, -0.7470]), tensor([0.3687])),\n",
       " (tensor([ 1.0150,  1.4429, -0.7470,  0.3687]), tensor([1.1705])),\n",
       " (tensor([ 1.4429, -0.7470,  0.3687,  1.1705]), tensor([0.3873])),\n",
       " (tensor([-0.7470,  0.3687,  1.1705,  0.3873]), tensor([-0.6518])),\n",
       " (tensor([ 0.3687,  1.1705,  0.3873, -0.6518]), tensor([0.2768])),\n",
       " (tensor([ 1.1705,  0.3873, -0.6518,  0.2768]), tensor([0.0758])),\n",
       " (tensor([ 0.3873, -0.6518,  0.2768,  0.0758]), tensor([-0.2658])),\n",
       " (tensor([-0.6518,  0.2768,  0.0758, -0.2658]), tensor([1.1221]))]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ac087de",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef3b1fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Model\n",
    "model = Model(context_size, n_embed, n_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f03e021",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 53.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xshape after pos torch.Size([4, 4])\n",
      "tensor([[-0.1115],\n",
      "        [-0.0648],\n",
      "        [-0.1115],\n",
      "        [-0.1149]], grad_fn=<TanhBackward0>) tensor([-0.8394])\n",
      "xshape after pos torch.Size([4, 4])\n",
      "tensor([[-0.2305],\n",
      "        [-0.1368],\n",
      "        [-0.2328],\n",
      "        [-0.2162]], grad_fn=<TanhBackward0>) tensor([0.0867])\n",
      "xshape after pos torch.Size([4, 4])\n",
      "tensor([[-0.2298],\n",
      "        [-0.2556],\n",
      "        [-0.2219],\n",
      "        [-0.2632]], grad_fn=<TanhBackward0>) tensor([0.0576])\n",
      "xshape after pos torch.Size([4, 4])\n",
      "tensor([[-0.1137],\n",
      "        [-0.0485],\n",
      "        [-0.1174],\n",
      "        [-0.0997]], grad_fn=<TanhBackward0>) tensor([0.2160])\n",
      "xshape after pos torch.Size([4, 4])\n",
      "tensor([[-0.1698],\n",
      "        [ 0.0134],\n",
      "        [-0.1739],\n",
      "        [-0.1403]], grad_fn=<TanhBackward0>) tensor([0.7177])\n",
      "xshape after pos torch.Size([4, 4])\n",
      "tensor([[-0.1805],\n",
      "        [ 0.0911],\n",
      "        [-0.1781],\n",
      "        [-0.1262]], grad_fn=<TanhBackward0>) tensor([1.0150])\n",
      "xshape after pos torch.Size([4, 4])\n",
      "tensor([[-0.1000],\n",
      "        [ 0.1743],\n",
      "        [-0.1137],\n",
      "        [-0.0670]], grad_fn=<TanhBackward0>) tensor([1.4429])\n",
      "xshape after pos torch.Size([4, 4])\n",
      "tensor([[-0.0905],\n",
      "        [ 0.2621],\n",
      "        [-0.0978],\n",
      "        [-0.0321]], grad_fn=<TanhBackward0>) tensor([-0.7470])\n",
      "xshape after pos torch.Size([4, 4])\n",
      "tensor([[-0.2772],\n",
      "        [-0.2170],\n",
      "        [-0.2554],\n",
      "        [-0.3729]], grad_fn=<TanhBackward0>) tensor([0.3687])\n",
      "xshape after pos torch.Size([4, 4])\n",
      "tensor([[-0.3022],\n",
      "        [-0.1518],\n",
      "        [-0.2886],\n",
      "        [-0.3390]], grad_fn=<TanhBackward0>) tensor([1.1705])\n",
      "xshape after pos torch.Size([4, 4])\n",
      "tensor([[-0.3707],\n",
      "        [-0.1960],\n",
      "        [-0.3674],\n",
      "        [-0.3976]], grad_fn=<TanhBackward0>) tensor([0.3873])\n",
      "xshape after pos torch.Size([4, 4])\n",
      "tensor([[-0.0876],\n",
      "        [ 0.0820],\n",
      "        [-0.1015],\n",
      "        [-0.0468]], grad_fn=<TanhBackward0>) tensor([-0.6518])\n",
      "xshape after pos torch.Size([4, 4])\n",
      "tensor([[-0.3323],\n",
      "        [-0.2676],\n",
      "        [-0.3097],\n",
      "        [-0.4236]], grad_fn=<TanhBackward0>) tensor([0.2768])\n",
      "xshape after pos torch.Size([4, 4])\n",
      "tensor([[-0.2666],\n",
      "        [-0.2470],\n",
      "        [-0.2538],\n",
      "        [-0.3361]], grad_fn=<TanhBackward0>) tensor([0.0758])\n",
      "xshape after pos torch.Size([4, 4])\n",
      "tensor([[-0.1375],\n",
      "        [-0.1512],\n",
      "        [-0.1272],\n",
      "        [-0.1717]], grad_fn=<TanhBackward0>) tensor([-0.2658])\n",
      "xshape after pos torch.Size([4, 4])\n",
      "tensor([[-0.1744],\n",
      "        [-0.0873],\n",
      "        [-0.1753],\n",
      "        [-0.1542]], grad_fn=<TanhBackward0>) tensor([1.1221])\n",
      "Epoch 1/1, Loss: 2.7715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    total_loss = 0\n",
    "    for x, y in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x)\n",
    "        print(outputs, y)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(x):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f37b2f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bc165b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gptoy",
   "language": "python",
   "name": "gptoy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
